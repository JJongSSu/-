LSTM
GRU
one-to-many
many-to-many

오토인코더
GAN

통계 : 독립변수로 종속변수를 설명, 데이터를 임의로 조작하면 안됨
머신러닝 : 독립변수로 종속변수를 예측, 예측만 잘한다면 데이터 조작 가능
딥러닝 : 비정형 데이터도 학습 가능, 전처리 필요 없음, 임베딩은 해야됨(숫자로 치환하는 과정)

<머신러닝>
문제정의
전처리 / 임베딩
모델 선언
모델 학습
예측

<딥러닝>
문제정의
input layer
hidden layer    순전파 ↓
output layer
손실함수
옵티마이저      역전파 ↑

활성화 함수에 1차함수는 사용하지 않음 -> 비선형 함수 사용
    ReLU
    tanh : 음수를 사용해야 되는 경우에 사용

output layer
    회귀 : linear -> 연속형 변수
    이진분류 : sigmoid
    다진분류 : softmax

손실함수
    회귀 : mse
    이진분류 : binary_crossentropy
    다진분류 : categorical_crossentropy 

옵티마이저
    경사하강법에서 방향, 움직이는 정도 조절
    momentum
        옵티마이저의 계산값과 이전 epoch에서 계산한 값을 벡터로 더함
        모델 : momentum

    시계열
        모델 : RMSP

    ADAM -> momentum + 시계열

CNN
    entropy가 낮으면 max pooling은 효율이 낮음 -> avg pooling 사용
    filtering으로 차원을 낮춤
    과대적합을 방지하기 위해 같은 데이터를 여러번 학습시키는게 중요
        -> 데이터 확장(이미지 증식)
    padding으로 데이터 크기를 일정하게 만들어 줌
    stride : 몇 픽셀씩 건너 뛸건지 결정
    sliding
    stride는 filter 크기보다 작아야 함

    Conv2D(filters, kernel_size, padding, input_shape=(28,28,1), activation, strides)
        input_shape에서 1, 3으로 흑백, RGB 선택

RNN
    시퀀스 모델 사용 -> 데이터 간 순서가 있을 때 사용
    다중공선성 방지를 위해 사용
    이전 hidden layer에서 예측했던 결과물과 현재 hidden layer에서 예측해야 되는 것을 합쳐서 같이 예측
    반어법을 구별할 때 시퀀스 개념을 사용하여 학습시켜 판단할 수 있게 함
    grid 매커니즘 : 장기적인 결과를 의식하지 않고 단기적으로만 알고리즘을 사용하는 것

LSTM
    장기로 기억할 정보와 단기로 기억할 정보를 구분
    모든 hidden state에는 classifier가 3개씩 들어있음
        forget gate -> 정보를 폐기할 것인지 분류
        input gate -> 다음 레이어를 학습할 때 정보를 사용할 것인지 분류
        output gate -> 최종 output을 예측할 때 사용할 것인지 분류
    계산 시간이 많음. 성능은 좋음

GRU
    LSTM를 경량화시켜서 만듬
    모두 x일 경우 왜 forget gate에서 o를 안했나?? -> forget과 input을 합침

    컨트롤러 = forget gate + input gate
    output gate

    LSTM보다 계산시간은 줄어들었지만 성능은 살짝 안좋음


                머신러닝
지도학습    비지도학습  오토인코더  강화학습
    o           x         자신     페널티
-> 레이블로 나뉨

오토인코더
    자기자신이 레이블
    원본데이터를 넣어서 원본데이터를 출력
    encoder(인코더) -> latent vector -> decoder(디코더)
        인코더 : 원본 데이터를 행렬로 분해
        디코더 : 분해한 것을 다시 원본 데이터로 복구
    인코더와 디코더에 DNN 사용(CNN, RNN 등으로 변경해서 사용할 수 있음)
    decoder는 latent vector만 보고 원본 데이터와 유사하게 복원하는 것이 목표
    encoder는 latent vector에 원본 데이터를 최대한 많이 넣는 것이 목표
    임베딩에 사용할 수 있음

    왜 원본 데이터를 행렬로 치환하고 다시 복구하나??
        1) 희소 오토인코더
            feature 개수를 제한, input data를 조작
            원본을 볼 수 있기 때문에 어떤 feature가 중요한지 알 수 있음

        2) 과소 완전 오토인코더
            중요 정보들만 추림, 중간 단계에서 data 조작, 모래시계 모양(50*50 -> 20*20 -> 50*50 : 중간 사이즈가 작거나 커야함)
            원본을 볼 수 있기 때문에 어떤 feature가 중요한지 알 수 있음

        3) 잡음 제거 오토인코더
            input data = 저화질 data
            output data = 고화질 data
            고화질 data로 만드는 방법을 학습

            옛날 영상에 PPL을 넣어서 상품성을 올려서 마케팅하는 방법들도 요즘 사용
            흑백영화를 색상영화로 만듬

        4) 적층 오토인코더 + 알파
            데이터를 encoder로 갈아서 유통 -> 갈린 데이터를 받아서 decoder 한 후 학습시킴
            이 때 decoder에서 사용하는 오토인코더
            보안용으로 사용(문서 유출 방지) -> 인코더의 파라미터가 없으면 풀 수 없음
            어플에 적용가능한지 -> 카메라 제한 어플은 있음

GAN
    랜덤 값 -> decoder -> data -> encoder -> 숫자형태 latent vector
    랜덤 값으로 디코더한 data가 진짜인지 가짜인지 예측하는 모델
    정확도가 올라가면 인코더 성능이 올라가는 것, 내려가면 디코더 성능이 올라가는 것
        -> 정확도만으로는 평가하기에는 힘듬
        -> 인간의 생각이 들어가야 됨
    가짜 data의 정교함을 올릴 때 사용 -> 인간을 속이기 위해 사용
    영상, 그림, 작곡
    가짜 그림, 자소서 찾기 -> encoder 성능 강화 : 가짜 데이터를 계속 주고 학습시킴
    딥페이크 -> 원본 + 합성 데이터를 input으로 넣고 진짜 같도록 만듬
    그림그리는 ai는 디코더의 성능을 높이는 것
    시뮬레이션을 돌려볼 수도 있음 -> 강화학습

    문제점
    1. encoder와 decoder 성능이 좋지 않으면 이상한 방향으로 갈 수 있다 -> 인코더를 먼저 학습시킨 후 사용(사람이 한 것 vs 아닌 것)
    2. 내쉬 균형 상태
        모든 정보가 공개되어 있다면 모든 현상은 내쉬 균형 상태가 된다
        1) 희소 오토인코더를 통해 어떤 부분에서 문제가 있는지 알 수 있음
            -> 해당 feature의 가중치를 빼거나 추가시킴
        2) 부족한 부분만 보충 학습시킴


