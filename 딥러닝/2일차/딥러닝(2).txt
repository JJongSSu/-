데이터                  input layer
전처리(임베딩)
학습                    hidden layer    ->  활성화 함수 : tanh, ReLU
출력                    output layer    -> 회귀 : linear, 이진분류 : sigmoid, 다진분류 : softmax
평가                    loss function   -> 회귀 : mse, 이진분류 : binary_crossentropy, 다진분류 : categorical_crossentropy 
조정, 최적화            optimizer       -> 벡터(정도와 방향) : 경사하강을 얼만큼? 어디 방향으로? / 방법 : 시계열(주기, 추세) -> 패턴(힘의 크기), 관성(momentum) -> 방향성
역전파

딥러닝 특징
    데이터 양 많아야 함 -> 경사하강법 사용
    성능은 좋지만 판단근거를 추적할 수 없음 -> feature 개수가 무한하기 때문

손실함수에서 최솟값을 찾는 방법 : 미분, 경사하강법(연산량이 많을 때)
