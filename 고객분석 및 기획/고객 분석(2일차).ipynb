{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네이버 카페 크롤러\n",
    "가입이 필수인 카페들은 조건을 만족시켜줘야 함\n",
    "1. 크롬 드라이버 제어(크롬창 켜기)\n",
    "2. 네이버 로그인(아이디 입력 -< 비밀번호 입력 -> 로그인 버튼 클릭 순서로 작업 진행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=8132a534e13a865f51a7ecd5af46fb2c6804fa26f78d288b31a589a49bd3ea5f\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.11.1 bs4-0.0.1 soupsieve-2.3.2.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.6.0-py3-none-any.whl (5.2 MB)\n",
      "     ---------------------------------------- 5.2/5.2 MB 20.8 MB/s eta 0:00:00\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "     ------------------------------------- 384.9/384.9 kB 25.0 MB/s eta 0:00:00\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting urllib3[socks]~=1.26\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\miniconda3\\envs\\pythonproject\\lib\\site-packages (from selenium) (2022.9.24)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting cffi>=1.14\n",
      "  Downloading cffi-1.15.1-cp38-cp38-win_amd64.whl (178 kB)\n",
      "     ------------------------------------- 178.8/178.8 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting idna\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting attrs>=19.2.0\n",
      "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 118.7/118.7 kB ? eta 0:00:00\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Installing collected packages: sortedcontainers, urllib3, sniffio, PySocks, pycparser, idna, h11, exceptiongroup, attrs, async-generator, wsproto, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed PySocks-1.7.1 async-generator-1.10 attrs-22.1.0 cffi-1.15.1 exceptiongroup-1.0.1 h11-0.14.0 idna-3.4 outcome-1.2.0 pycparser-2.21 selenium-4.6.0 sniffio-1.3.0 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.12 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting webdriver_manager\n",
      "  Using cached webdriver_manager-3.8.4-py2.py3-none-any.whl (27 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Collecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 kB ? eta 0:00:00\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\envs\\pythonproject\\lib\\site-packages (from requests->webdriver_manager) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from requests->webdriver_manager) (1.26.12)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from tqdm->webdriver_manager) (0.4.6)\n",
      "Installing collected packages: tqdm, python-dotenv, charset-normalizer, requests, webdriver_manager\n",
      "Successfully installed charset-normalizer-2.1.1 python-dotenv-0.21.0 requests-2.28.1 tqdm-4.64.1 webdriver_manager-3.8.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dotenv.exe is installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting selenium==3.141.0\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from selenium==3.141.0) (1.26.12)\n",
      "Installing collected packages: selenium\n",
      "  Attempting uninstall: selenium\n",
      "    Found existing installation: selenium 4.6.0\n",
      "    Uninstalling selenium-4.6.0:\n",
      "      Successfully uninstalled selenium-4.6.0\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install webdriver_manager\n",
    "!pip install selenium==3.141.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (3.8.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from webdriver_manager) (0.21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from webdriver_manager) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from webdriver_manager) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from requests->webdriver_manager) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\envs\\pythonproject\\lib\\site-packages (from requests->webdriver_manager) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from requests->webdriver_manager) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from tqdm->webdriver_manager) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.1-cp38-cp38-win_amd64.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 24.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.8.2)\n",
      "Collecting numpy>=1.20.3\n",
      "  Downloading numpy-1.23.4-cp38-cp38-win_amd64.whl (14.7 MB)\n",
      "     --------------------------------------- 14.7/14.7 MB 29.7 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "     ------------------------------------- 498.1/498.1 kB 32.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.23.4 pandas-1.5.1 pytz-2022.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4832\\161475440.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n"
     ]
    }
   ],
   "source": [
    "#크롬 드라이버 제어\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dex-shm-usage')\n",
    "\n",
    "# 현재 컴퓨터 크롬 드라이버 위치\n",
    "chrome_path = 'chromedriver.exe'    # 본인의 크롬 드라이버 위치 입력\n",
    "\n",
    "# 자동화된 크롬 창 실행\n",
    "driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 로그인 페이지 접속\n",
    "login_url = 'https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com'\n",
    "driver.get(login_url)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# 본인의 아이디, 비밀번호를 각 변수에 저장\n",
    "my_id = 'dlwnsrl8964'\n",
    "my_pw = 'dustnrh31322!'\n",
    "\n",
    "# 보통 사이트에서는 send_key 사용하는데 네이버는 자동입력방지 기능 때문에 다른 방법 사용\n",
    "# 아이디, 비밀번호 입력 (네이버에 로그인 할 경우 'send_keys()' 함수가 아니라 'execute_script()' 사용)\n",
    "#네이버에서 send_key()를 쓰면 로그인에서 자동입력방지기능이 나타남.\n",
    "driver.execute_script(\"document.getElementsByName('id')[0].value = \\'\" + my_id + \"\\'\")\n",
    "driver.execute_script(\"document.getElementsByName('pw')[0].value = \\'\" + my_pw + \"\\'\")\n",
    "time.sleep(1)\n",
    "\n",
    "# 로그인 버튼 클릭\n",
    "driver.find_element('id','log.login').click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카페 접속\n",
    "time.sleep(2)\n",
    "moms_url = 'https://cafe.naver.com/firenze'\n",
    "driver.get(moms_url)\n",
    "time.sleep(1)\n",
    "\n",
    "# 원하는 게시판 클릭\n",
    "driver.find_element('xpath','//*[@id=\"menuLink123\"]').click()\n",
    "time.sleep(1)\n",
    "\n",
    "# 프레임 전환\n",
    "driver.switch_to.frame('cafe_main')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 게시물 크롤링\n",
    "1. 첫번째 게시물 클릭 : XPath 활용\n",
    "2. 크롤링할 개수 지정\n",
    "3. 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1-cp38-cp38-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 19.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mXPATH,\u001b[39m'\u001b[39m\u001b[39m//*[@id=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmain-area\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]/div[4]/table/tbody/tr[1]/td[1]/div[2]/div/a\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mclick()\n\u001b[0;32m     11\u001b[0m \u001b[39m# 2번 : for문으로 지정한 게시물 개수까지 돌림\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# 많은 양 크롤링할 경우 메모리 과부하로 크롤링이 멈출 수 있음\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m# 이 때 이미 받은 data들이 날아가지 않도록 for문을 이용해 지정\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39;49m(\u001b[39m1\u001b[39;49m)):  \u001b[39m# 새로 창 열기\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m30\u001b[39m)): \u001b[39m# 한 번에 몇개의 게시물을 크롤링할 것인가, 컴퓨터 성능에 따라 개수 달라짐(~5000개)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         driver\u001b[39m.\u001b[39mimplicitly_wait(\u001b[39m30\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# 제목, 본문, 댓글, 날짜 list 생성\n",
    "titles = []\n",
    "contents = []\n",
    "reviews = []\n",
    "dates = []\n",
    "count_views = 0\n",
    "\n",
    "# 1번\n",
    "driver.find_element(By.XPATH,'//*[@id=\"main-area\"]/div[4]/table/tbody/tr[1]/td[1]/div[2]/div/a').click()\n",
    "\n",
    "# 2번 : for문으로 지정한 게시물 개수까지 돌림\n",
    "# 많은 양 크롤링할 경우 메모리 과부하로 크롤링이 멈출 수 있음\n",
    "# 이 때 이미 받은 data들이 날아가지 않도록 for문을 이용해 지정\n",
    "for i in tqdm(range(1)):  # 새로 창 열기\n",
    "    for i in tqdm(range(30)): # 한 번에 몇개의 게시물을 크롤링할 것인가, 컴퓨터 성능에 따라 개수 달라짐(~5000개)\n",
    "        driver.implicitly_wait(30)\n",
    "        # 제목 수집\n",
    "        time.sleep(random.uniform(0.5,1))   # 크롤링하다가 막히는 걸 방지하기 위해 최대한 사람처럼 보이게 만들어 줌 \n",
    "        title = driver.find_element(By.XPATH,'//*[@id=\"app\"]/div/div/div[2]/div[1]/div[1]/div/h3').text\n",
    "        titles.append(title)\n",
    "\n",
    "        # 본문 수집\n",
    "        # 3가지 경우 발생 : 기본적인 본문, 사진으로만 구성된 본문, 수정을 통해 다른 선택자 생김\n",
    "        try:\n",
    "            content = driver.find_element(By.CSS_SELECTOR,'div.se-module.se-module-text')\n",
    "            contents.append(content)\n",
    "        except:\n",
    "            try:\n",
    "                content = driver.find_element(By.CSS_SELECTOR,'div.ContentRenderer')\n",
    "                # 다른 선택자가 생긴 경우\n",
    "            except:\n",
    "                content=[]  # 본문이 사진으로만 구성된 경우 빈칸으로 가져옴(사진 가져오게 할 수도 있음)\n",
    "                contents.append(content)\n",
    "\n",
    "        # 댓글 수집(댓글이 있는 경우, 없는 경우)\n",
    "        soup = bs(driver.page_source, 'lxml') # 현재 페이지 HTML 정보 가지오 오기\n",
    "        iscomment = review.find_all('span', class_='text_comment')\n",
    "        if (len(iscomment)==0):   # 댓글 없는 경우\n",
    "            review = []\n",
    "        else:   # 댓글 있는 경우\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'text_comment')))\n",
    "            # 웹드라이버를 통해 브라우저에서 최대 15초 기다려주고, text_comment(댓글 선택)\n",
    "            soup = bs(driver.page_source, 'lxml')\n",
    "            iscomment = review.find_all('span', class_='text_comment')\n",
    "            review = []\n",
    "            for i in iscomment:\n",
    "                review.append([i.get_text()])\n",
    "\n",
    "        reviews.append(review)\n",
    "\n",
    "        # 날짜 수집\n",
    "        date = driver.find_element(By.XPATH,'//*[@id=\"app\"]/div/div/div[2]/div[1]/div[2]/div/div[2]/span[1]').text\n",
    "        dates.append(date)\n",
    "\n",
    "        # count_views 크롤링 진행상황(50개마다 출력)\n",
    "        count_views = count_views + 1\n",
    "        if (count_views%50==0):\n",
    "            print(\"게시물 크롤링 완료\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # 다음글 클릭(다음글 버튼 클릭해서 연속적으로 크롤링)\n",
    "        try:\n",
    "            driver.find_element(By.CSS_SELECTOR,'#app > div > div > div.ArticleTopBtns > div.right_area > a.BaseButton.btn_next.BaseButton--skinGray.size_default')\n",
    "            driver.implicitly_wait(20)\n",
    "\n",
    "        except: # 다음글 버튼 사라지는 문제점 발생, 크롬 close 후 다시 open\n",
    "            current_url = driver.current_url    # 다음ㄱ믈 버튼이 사라져서 크롤링이 멈춘 url 가져오기\n",
    "            driver.close()\n",
    "\n",
    "            # 크롬창 다시열기\n",
    "            driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n",
    "\n",
    "            # 재로그인\n",
    "            login_url = 'https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com'\n",
    "            driver.get(login_url)\n",
    "            driver.implicitly_wait(10)\n",
    "\n",
    "            driver.execute_script(\"document.getElementsByName('id')[0].value = \\'\" + my_id + \"\\'\")\n",
    "            driver.execute_script(\"document.getElementsByName('pw')[0].value = \\'\" + my_pw + \"\\'\")\n",
    "            time.sleep(1)\n",
    "\n",
    "            driver.find_element('id','log.login').click()\n",
    "            time.sleep(1)\n",
    "\n",
    "        # 크롬이 다시 열릴 때 가지고 올 다음글 링크(herf 추출)\n",
    "        link = driver.find_element(By.XPATH,'//*[@id=\"main-area\"]/div[4]/table/tbody/tr[2]/td[1]/div[2]/div/a').get_attribute('href')\n",
    "\n",
    "        # 현재 크롬창 닫기\n",
    "        driver.close()\n",
    "\n",
    "        # 다시 열기\n",
    "        driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n",
    "\n",
    "        # 재로그인\n",
    "        login_url = 'https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com'\n",
    "        driver.get(login_url)\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        driver.execute_script(\"document.getElementsByName('id')[0].value = \\'\" + my_id + \"\\'\")\n",
    "        driver.execute_script(\"document.getElementsByName('pw')[0].value = \\'\" + my_pw + \"\\'\")\n",
    "        time.sleep(1)\n",
    "\n",
    "        driver.find_element('id','log.login').click()\n",
    "        time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b41067d333ae5a9f55b6c28201bd8f20eb97371436f57b1f1425e7e396b7af99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
