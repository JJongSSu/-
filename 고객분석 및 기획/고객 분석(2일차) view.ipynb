{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: certifi\n",
      "Version: 2022.9.24\n",
      "Summary: Python package for providing Mozilla's CA Bundle.\n",
      "Home-page: https://github.com/certifi/python-certifi\n",
      "Author: Kenneth Reitz\n",
      "Author-email: me@kennethreitz.com\n",
      "License: MPL-2.0\n",
      "Location: c:\\programdata\\miniconda3\\envs\\pythonproject\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: requests\n"
     ]
    }
   ],
   "source": [
    "!pip show certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities #다음화면으로 빨리 넘어갈때\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException #selenium 이용시 Alert을 제어\n",
    "import urllib.request\n",
    "import random\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view는 스크롤을 계속 내리는 코드를 작성해줘야 됨\n",
    "# 스크롤을 끝까지 내린 후 링크를 모두 수집\n",
    "# 수집한 링크를 하나씩 들어가서 데이터 수집\n",
    "# 월별로 최대 1000개 크롤링 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['을지로인스타술집', '신당인스타술집', '을지로이색술집', '신당이색술집', '을지로감성술집', '신당감성술집', '을지로컨셉술집', '신당컨셉술집']\n"
     ]
    }
   ],
   "source": [
    "# 크롤링 시작과 끝 날짜(달 별로 크롤링)\n",
    "first_days = pd.date_range('2021/01/01','2021/01/31', freq='MS')   # 각 달의 첫 날\n",
    "last_days = pd.date_range('2021/01/01','2021/01/31', freq='M')  # 각 달의 마지막 날\n",
    "\n",
    "# keyword_list = ['인스타술집','이색술집','감성술집', '담금술집', '분위기술집', '정글포차', '인테리어술집', '새로운술집', '감성주점', '컨셉술집'] # 검색키워드 추가\n",
    "# 지역 선정 방법 어떻게??\n",
    "# keyword를 한줄로 검색해서 크롤링\n",
    "\n",
    "keyword_main = ['인스타술집','이색술집','감성술집', '컨셉술집']\n",
    "keyword_sub = ['을지로', '신당']\n",
    "keyword_list = []\n",
    "for i in keyword_main:\n",
    "    for j in keyword_sub:\n",
    "        keyword_list.append(j+i)\n",
    "print(keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롬드라이버 제어\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox') #bypass OS security model\n",
    "chrome_options.add_argument('--disable-dex-shm-usage')#overcome limited resource problems\n",
    "# options.add_argument('--headless') # 브라우저 백그라운드 모드\n",
    "\n",
    "chrome_path = 'chromedriver.exe' #현재 컴퓨터의 크롬드라이버 위치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12256\\1590242383.py:8: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "술집 키워드 2021년 1월 990 개 블로그 url 주소 수집\n",
      "인스타 키워드 2021년 1월 30 개 블로그 url 주소 수집\n",
      "이색 키워드 2021년 1월 990 개 블로그 url 주소 수집\n",
      "감성 키워드 2021년 1월 30 개 블로그 url 주소 수집\n"
     ]
    }
   ],
   "source": [
    "# 블로그 주소 수집\n",
    "blog_url_list = []\n",
    "\n",
    "# 네이버에 키워드 검색\n",
    "for keyword in keyword_list:\n",
    "    url = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=blog&query={}&oquery={}'.format(keyword, keyword)\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    url_want = 990  # 월별 1000개까지만 가능하기 때문에 개수 설정\n",
    "\n",
    "    driver.find_element('xpath','//*[@id=\"snb\"]/div[1]/div/div[2]/a').click() #검색 옵션 클릭\n",
    "\n",
    "    # 날짜 지정\n",
    "    for k in range(len(first_days)):\n",
    "        try:\n",
    "            # 시작과 끝의 년월일 설정\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[1]/a[9]/i').click() #직접 입력\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(first_days.year[k]-2002)).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(first_days.month[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(first_days.day[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[1]/span[3]/a').click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(last_days.year[k]-2002)).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(last_days.month[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(last_days.day[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[3]/button').click()\n",
    "\n",
    "            # 스크롤 조작\n",
    "            last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "            scroll = (url_want/30)-1    # 한 페이지에 기본으로 30개 글이 나옴\n",
    "            \n",
    "            # 스크롤 다운\n",
    "            for i in range(int(scroll)):\n",
    "                driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')  # 0부터 끝까지 스크롤 내림\n",
    "                time.sleep(random.uniform(1,1.7))\n",
    "                \n",
    "                new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "                if(new_height == last_height):\n",
    "                    break\n",
    "\n",
    "                last_height = new_height\n",
    "\n",
    "            soup = bs(driver.page_source, 'lxml')\n",
    "            blog_url = soup.find_all('a', class_ = 'api_txt_lines total_tit')   # 첫번째 view 제목 class\n",
    "\n",
    "            # url 주소 수집\n",
    "            for i in blog_url:\n",
    "                blog_url_list.append(i['href']) # 주소 수집\n",
    "            \n",
    "            print(f'{keyword} 키워드 {first_days.year[k]}년 {first_days.month[k]}월', len(blog_url), '개 블로그 url 주소 수집') \n",
    "\n",
    "            driver.execute_script('window.scrollTo(0,0)')   # 스크롤 밑으로 내려가지 않게 해줌\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blog_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강사님 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 블로그 주소 수집\n",
    "\n",
    "# blog_url_list = []\n",
    "\n",
    "# #네이버에 키워드 검색\n",
    "# for keyword in keyword_list:\n",
    "#     url = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=blog&query={}&oquery={}'.format(keyword, keyword)\n",
    "        \n",
    "#     driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n",
    "#     driver.implicitly_wait(3)\n",
    "    \n",
    "#     driver.get(url)\n",
    "#     time.sleep(3)\n",
    "    \n",
    "#     url_want = 990 #\n",
    "    \n",
    "#     driver.find_element('xpath','//*[@id=\"snb\"]/div[1]/div/div[2]/a').click() #검색 옵션 클릭\n",
    "\n",
    "#     #날짜 지정\n",
    "#     for k in range(len(first_days)):\n",
    "#         try:\n",
    "#             #시작과 끝의 년월일 설정\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[1]/a[9]/i').click() #직접 입력\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(first_days.year[k]-2002)).click()\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(first_days.month[k])).click()\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(first_days.day[k])).click()\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[1]/span[3]/a').click()\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(last_days.year[k]-2002)).click()\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(last_days.month[k])).click()\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(last_days.day[k])).click()\n",
    "#             driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[3]/button').click()            \n",
    "            \n",
    "            \n",
    "#             # 스크롤 조작\n",
    "#             last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "            \n",
    "#             scroll = (url_want/30)-1 #한 페이지에 기본으로 30개 글이 나옴\n",
    "            \n",
    "#             # 스크롤 다운\n",
    "#             for i in range(int(scroll)):\n",
    "#                 driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "#                 time.sleep(random.uniform(1,1.7))\n",
    "                \n",
    "#                 new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "                \n",
    "#                 if new_height == last_height:\n",
    "#                     break\n",
    "                    \n",
    "#                 last_height = new_height\n",
    "                \n",
    "                \n",
    "#             soup = bs(driver.page_source, 'lxml')\n",
    "#             blog_url = soup.find_all('a',class_='api_txt_lines total_tit')\n",
    "            \n",
    "#             # url 주소 수집\n",
    "#             for i in blog_url:\n",
    "#                 blog_url_list.append(i['href']) #주소 수집\n",
    "                \n",
    "#             print('{0} 키워드 {1}년{2}월'.format(keyword, \n",
    "#                                             first_days.year[k], frist_days.month[k]), \n",
    "#                   len(blog_url),'개 블로그 url 주소 수집')\n",
    "            \n",
    "            \n",
    "#             driver.execute_script('window.scrollTo(0,0)')\n",
    "            \n",
    "#         except:\n",
    "#             pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2038"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수집 후 url list 중복 확인\n",
    "real_list = set(blog_url_list)\n",
    "blog_url_list = list(real_list)\n",
    "len(blog_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장(블로그 주소)\n",
    "k = pd.DataFrame(blog_url_list)\n",
    "k.to_csv('url_list_술집.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 블로그 크롤링\n",
    "url = pd.read_csv('url_list_술집.csv')\n",
    "blog_url_list = list(url['0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_naver_blog1=[]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "time_list = [] #시간\n",
    "review_list = [] #리뷰\n",
    "comment_list = [] #댓글\n",
    "like_list = [] #좋아요수\n",
    "url_list = [] #url주소\n",
    "count = 0\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options) #크롬 드라이버 위치만 바꿔주시면 됩니다.\n",
    "for url in blog_url_list: #기본적으로 고치지 않으시지만, n번째 크롤링에서 멈췄다면, blog_url_list를 blog_url_list[n:]으로 고칩니다.\n",
    "    if 'naver' in url: #네이버 블로그만 수집(다른 사이트가 섞이면 크롤링 에러가 남)\n",
    "    \n",
    "        count += 1\n",
    "        driver.get(url) #url 하나씩 글을 수집할꺼야\n",
    "        time.sleep(1)\n",
    "\n",
    "        try:\n",
    "            # 전체 본문 가지고 와서\n",
    "            driver.switch_to.frame('mainFrame') #네이버는 mainFrame을 바꿔줘야 수집이 됌\n",
    "            time.sleep(1)\n",
    "        \n",
    "            soup = bs(driver.page_source, 'lxml') #뷰티풀숩을 이용해서 구문 분석(lxml 파싱 이용. 모든 테그에서 데이터를 추출위함)\n",
    "            postview = soup.find('div', attrs={'id': re.compile('post-view.+')}).get_text()\n",
    "\n",
    "            reg = re.compile(r'[\\s+]') #r은 raw string. \\s+는 공백문자\n",
    "            postview_reg = reg.sub(' ',postview) #공백을 띄어쓰기로 대치해서 본문 글 수집\n",
    "            try:\n",
    "                # 좋아요수\n",
    "                like = driver.find_element(\"xpath\", \"//span[@class='u_likeit_list_btn _button btn_sympathy pcol2 off']/em[@class='u_cnt _count']\")\n",
    "                like = like.text\n",
    "            except:\n",
    "                like = [] #좋아요 없으면 빈 리스트\n",
    "            \n",
    "            try:\n",
    "                timeline = driver.find_element(\"xpath\", \"//span[@class='se_publishDate pcol2']\") #수정 안 한 경우\n",
    "        \n",
    "            except:\n",
    "                timeline = driver.find_element(\"xpath\", \"//p[@class='date fil5 pcol2 _postAddDate']\") #수정 한 경우\n",
    "            timeline = timeline.text\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.CSS_SELECTOR,'span.btn_arr').click() #댓글 내리는 버튼(태그명.클래스선택자)\n",
    "                #driver.find_element_by_css_selector('span.btn_arr').click()\n",
    "                time.sleep(1.7)\n",
    "\n",
    "                comment_blog = []\n",
    "                comment = driver.find_element(By.CSS_SELECTOR,'span.u_cbox_contents') #댓글\n",
    "                #comment = driver.find_elements_by_css_selector('span.u_cbox_contents')\n",
    "                for i in comment: #댓글 수집\n",
    "                    com = str(i.text) #\n",
    "                    com = reg.sub(' ',com) \n",
    "                    comment_blog.append(([com]))\n",
    "            except: \n",
    "                comment_blog = []\n",
    "             \n",
    "            time_list.append(timeline)\n",
    "            review_list.append(postview_reg)\n",
    "            comment_list.append(comment_blog)\n",
    "            url_list.append(url)\n",
    "            like_list.append(like)\n",
    "            time.sleep(random.uniform(1,1.6))\n",
    "        except UnexpectedAlertPresentException:\n",
    "            pass\n",
    "    else:\n",
    "        no_naver_blog1.append(url)\n",
    "        print('네이버 블로그 아닌 url: ',url)\n",
    "        \n",
    "    if count%10 ==0:\n",
    "        print('{}개 블로그 크롤링 완료'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링 소요 시간:  201.99278736114502\n",
      "총 33개 블로그 크롤링 완료\n"
     ]
    }
   ],
   "source": [
    "data = {'time':time_list, 'review':review_list, 'comment':comment_list, 'like':like_list, 'url':url_list}\n",
    "df = pd.DataFrame(data)\n",
    "print('크롤링 소요 시간: ', time.time()-start)\n",
    "print('총 {}개 블로그 크롤링 완료'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column명 정의"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b41067d333ae5a9f55b6c28201bd8f20eb97371436f57b1f1425e7e396b7af99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
