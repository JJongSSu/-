{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "from konlpy.tag import Okt\n",
    "from nltk.util import everygrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "JVMNotFoundException",
     "evalue": "No JVM shared library file (libjli.dylib) found. Try setting up the JAVA_HOME environment variable properly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJVMNotFoundException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#원하는 태그 추출 & 불용어 제거\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m okt \u001b[39m=\u001b[39m Okt()\n\u001b[1;32m      4\u001b[0m \u001b[39m#불용어\u001b[39;00m\n\u001b[1;32m      5\u001b[0m stopwords \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../teambearable/ko-stopwords.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#한국어불용어사전 불러오기\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/konlpy/tag/_okt.py:51\u001b[0m, in \u001b[0;36mOkt.__init__\u001b[0;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, jvmpath\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_heap_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m jpype\u001b[39m.\u001b[39misJVMStarted():\n\u001b[0;32m---> 51\u001b[0m         jvm\u001b[39m.\u001b[39;49minit_jvm(jvmpath, max_heap_size)\n\u001b[1;32m     53\u001b[0m     oktJavaPackage \u001b[39m=\u001b[39m jpype\u001b[39m.\u001b[39mJPackage(\u001b[39m'\u001b[39m\u001b[39mkr.lucypark.okt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m     OktInterfaceJavaClass \u001b[39m=\u001b[39m oktJavaPackage\u001b[39m.\u001b[39mOktInterface\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/konlpy/jvm.py:55\u001b[0m, in \u001b[0;36minit_jvm\u001b[0;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m args \u001b[39m=\u001b[39m [javadir, os\u001b[39m.\u001b[39msep]\n\u001b[1;32m     53\u001b[0m classpath \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m folder_suffix]\n\u001b[0;32m---> 55\u001b[0m jvmpath \u001b[39m=\u001b[39m jvmpath \u001b[39mor\u001b[39;00m jpype\u001b[39m.\u001b[39;49mgetDefaultJVMPath()\n\u001b[1;32m     57\u001b[0m \u001b[39m# NOTE: Temporary patch for Issue #76. Erase when possible.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdarwin\u001b[39m\u001b[39m'\u001b[39m\\\n\u001b[1;32m     59\u001b[0m         \u001b[39mand\u001b[39;00m jvmpath\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m1.8.0\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\\\n\u001b[1;32m     60\u001b[0m         \u001b[39mand\u001b[39;00m jvmpath\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mlibjvm.dylib\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jpype/_jvmfinder.py:74\u001b[0m, in \u001b[0;36mgetDefaultJVMPath\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     finder \u001b[39m=\u001b[39m LinuxJVMFinder()\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m finder\u001b[39m.\u001b[39;49mget_jvm_path()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/jpype/_jvmfinder.py:212\u001b[0m, in \u001b[0;36mJVMFinder.get_jvm_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m jvm_notsupport_ext \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[39mraise\u001b[39;00m jvm_notsupport_ext\n\u001b[0;32m--> 212\u001b[0m \u001b[39mraise\u001b[39;00m JVMNotFoundException(\u001b[39m\"\u001b[39m\u001b[39mNo JVM shared library file (\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mfound. Try setting up the JAVA_HOME \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39menvironment variable properly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m                            \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libfile))\n",
      "\u001b[0;31mJVMNotFoundException\u001b[0m: No JVM shared library file (libjli.dylib) found. Try setting up the JAVA_HOME environment variable properly."
     ]
    }
   ],
   "source": [
    "#원하는 태그 추출 & 불용어 제거\n",
    "okt = Okt()\n",
    "\n",
    "#불용어\n",
    "stopwords = pd.read_csv('../teambearable/ko-stopwords.csv') #한국어불용어사전 불러오기\n",
    "stopwords=list(stopwords['stopwords'])\n",
    "stopwords.extend(['에서','고','이다','는','한','씨', \"것\",\"거\",\"게\",\"데\",\"이다\",\"건\",\"고\",\"되다\",\"되어다\",\"걸\",\"기\",\n",
    "                  \"시\",\"네\",\"듯\",\"랍니\",\"중이\",\"얘\",\"스\",\"도도\", \"나\",\"수\",\"개\",\"내\",\"기\",\"제\",\"저\",\"인\",\"있다\",\"이렇다\",\n",
    "                  \"그렇다\",\"번\",\"위\",\"팅\",\"분\",\"인\",\"링\",\"란\",\"포\",\"두\", \"진짜\", \"하다\" ,\"이다\" ,\"가다\", \"이제\" ,\"들다\",\n",
    "                 '에서','고','이다','젛','뇨','껀데','뭘'\n",
    "                 ,'최고','느리다','마을','최고','항상','포장','재다','말다','목','넘김','만족하다','정말','역시','아주','감사하다','오다','자주','요','늘','넘다','않다','더','병','다','숙성','나다','술','드리다','마트','꼼꼼하다','잇다'\n",
    "                 ,'복','순도','용','비싸다','가격','많다','강하다','보내다','추천','보고','쏘다','느낌','사다','처음','많이','톡','생각','엄청','날','아니다'\n",
    "                 ,'믿다', '구입', '사먹다', '한번', '싶다', '콤', '완전', '제품', '재', '해주다', '말', '사람','특별하다','언제나','빨르다','두번째','전','계속','달'\n",
    "                 ,'추석', '인생', '최애', '명절', '해', '중', '생각나다', '시원하다', '다르다', '알다', '가족', '정도', '기대', '친구', '괜찮다', '부모님', '지인', '아직'\n",
    "                 ,'만족스럽다', '빼다', '상품', '굿', '못', '도', '기분', '다시', '주다', '즐기다', '맞다', '맛보다', '제일', '집', '입맛', '모르다', '먹기'\n",
    "                 ,'조심하다', '따다', '차다', '엄마', '예정', '만족', '감', '일반', '파다', '막', '근데', '별로', '적당하다','예전', '가끔', '유명하다', '만', '뚜껑', '매우', '기대하다', '의사', '한잔', '신선하다', '느끼다', '그냥', '아쉽다'\n",
    "                 ,'오픈', '쎄다', '여자', '호불호', '꼭', '벌써', '버리다', '이렇게', '돼다', '크다', '느껴지다','고급', '종종', '어울리다', '알', '남편', '빨리', '어른', '소문', '아버지', '마시기', '할인', '살다'\n",
    "                 ,'풍부하다', '모임', '해드리다', '빠지다', '나서다', '원래', '아빠', '걸리다', '안', '도착', '없이'\n",
    "                 ,'하루', '딱이다', '상태', '향', '후', '설', '주변', '사서', '때문', '반하다', '연말'\n",
    "                 ,'해봤다', '강추', '찾다', '자꾸', '살짝', '몇번', '빨', '요즘', '신세계', '사진', '생일'\n",
    "                 ,'빠르다', '자다', '구매', '마시다', '받다', '보다', '없다', '새다', '숙취', '아스파탐', '대포', '넘어가다','주가'\n",
    "                 ,'지나다', '무', '머리', '편하다', '아프다', '두다', '인터넷', '택배', '숙성하다', '일주일', '봄', '배달', '만들다', '애용', '냉장고'\n",
    "                 ,'여름', '잔', '앞', '며칠', '팔다', '달라지다', '가장', '변하다', '번창', '안전하다', '젤', '배상면', '건강하다', '굿굿'\n",
    "                 ,'따르다', '이용', '확실하다', '날짜', '시중', '들어가다', '첨가', '유통', '아이스팩', '제조', '넣다', '생', '다양하다','종류','들어가다','전통주','마켓','술술','후기','사보다','부담','여러가지','리뷰','블루'\n",
    "                 ,'인기','궁금하다','대상','무난','취향','적다','단','평이','이용','터지다','맘','/n'\n",
    "                 ]\n",
    "                 +'회랑 회 따뜻하다 나쁘다 튼튼하다 끄다 끝 장인어른 일품 파손 싸다 술맛 비다 착하다 명인 증류 안동소주 안동 뒤끝 박다 신랑 비다 뒤끝 품질 짜다 용이 외국인 지고 지다 높다 어르신 신분 명인 보이다 준비 쇼핑 밤 서울 실향 스컬 낮다 가볍다 섞다 귀엽다 명랑 버전 꼼꼼 볼 대중 패키지 높다 하이 널 타 써다 집들이 실향 원주 긋다 술맛 술집 패키지 결의 증류주 섞다 타 이름 인공 약 높다 감기 대중 인위 짜다 막걸리 대접 볼 관심 타 남다 기회 하이 볼 섞다 향기 도주 집들이 독하다 이름 파티 어떻다 워낙 보기 마치다 가미 다기 수고 맛잇을걱닡아 모으다 햡 담날 대박 물맛 안되다 읺았어 짜다 빠져들다 소비 안나 이색 보리 빨랏 부족하다 화이팅 편 감홍 쇼핑 대다 도자기 생신 술맛 지다 높다 개봉 준비 깊다 볼 외국 아버님 조명 이벤트 용이 얼 눈 신분 보기 작다 내기 불빛 사은 비주 즐겁다 준비 생신 아깝다 주신 싸다 품 아버님 비쥬 조명도 반응 켜다 고맙다 동학 저렴하다 청 서비스 술잔 소주 강쇠주 오메 기술 조선 대비 요리 사용 데우다 조사 쓰다 감사 음식 알콜 경험 청주 강쇠 가성 전주 모주 뜨다 신기하다 화주 좋아하다 주문 예쁘다 이쁘다 얼음 산 토닉 워터 빨대 깨지다 빙 탄복 박스 약하다 국산 오프너 위트 소백산 제공 분위기 아내 크리스마스 마음 마루 베베 솔직하다 초보자 와이프 작성 위트 디자인 굳다 달다 시큼하다 달달 선물 깔끔하다 뒤 비비 이 있 하 것 들 그 되 수 이 보 않 없 나 사람 주 아니 등 같 우리 때 년 가 한 지 대하 오 말 일 그렇 위하 기한 달라 첫날 첨 주말 걱정 전이 이유 해보다 저번 보지 함 기대다 상 비 베스트 도수 음 존맛 개인'.split()\n",
    "                 ) #불용어 추가\n",
    "stopwords=set(stopwords) # 중복제거\n",
    "\n",
    "# 형태소 분석 함수 만들기\n",
    "def okt_pos_tagging2(string):\n",
    "    pos_words = okt.pos(string, stem=True, norm=True) # 형태소 분석. 단어는 사전형으로 바꿔주기\n",
    "    words = [word for word, tag in pos_words if tag\n",
    "             in ['Noun', 'Adjective', 'Verb','Adverb'] if word not in stopwords ]\n",
    "\n",
    "    # n_gram 만들기\n",
    "    egram = list(everygrams(words, min_len=1, max_len=1))\n",
    "    egram_token = [' '.join(grams) for grams in egram]\n",
    "\n",
    "    return egram_token\n",
    "\n",
    "def okt_pos_tagging(string):\n",
    "    pos_words = okt.pos(string, stem=True, norm=True) # 형태소 분석. 단어는 사전형으로 바꿔주기\n",
    "    words = [word for word, tag in pos_words if tag\n",
    "             in ['Noun', 'Adjective', 'Verb','Adverb'] if word not in stopwords ]\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "\n",
    "data = pd.read_csv(\"../MF_keywordTest_ver.01.csv\", encoding='utf-8-sig')\n",
    "data.columns = ['book', 'author','content','recommend','record','a','b','c']\n",
    "del data['a']\n",
    "del data['b']\n",
    "del data['c']\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "globals()[\"MF_키워드분석Test_ver.01.csv\"] = data\n",
    "all_data = pd.concat([all_data,data],axis=0)\n",
    "all_data.drop(all_data.index[9:16], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=okt_pos_tagging)\n",
    "tfidf_fit = tfidf.fit(all_data.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징을 추출할 문서의 tf-idf를 구함\n",
    "a = \"MF_키워드분석Test_ver.01.csv\"\n",
    "bow_rep_tfidf = tfidf_fit.transform(globals()[a].record.apply(lambda x: np.str_(x)))\n",
    "word_count = pd.DataFrame({\n",
    "    '단어': tfidf.get_feature_names_out(),\n",
    "    'tf-idf': bow_rep_tfidf.sum(axis=0).flat,\n",
    "    'idf': tfidf.idf_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count.sort_values('tf-idf',ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf 가 높을수록 잘 안나오는 단어\n",
    "# tf-idf 가 높을수록 중요한 단어\n",
    "# 두값을 적절히 조정해서 특징 추출\n",
    "\n",
    "word_count.sort_values('tf-idf',ascending=False).head(50)[word_count['idf']>4.5][word_count['tf-idf'] * (len(all_data)/len(globals()[a]))>200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징을 추출할 문서의 tf-idf를 구함\n",
    "a3 = [\"막걸리_복순도가\",\"막걸리_느린마을\",\"막걸리_죽향도가\",\"탁주_모주\",\"탁주_이화주\"]\n",
    "Tags3 = {\"boksundoga\": [],\"maeul\": [],\"jukhyang\": [],\"moju\": [],\"ihwa\": []}\n",
    "keys3 = [\"boksundoga\",\"maeul\",\"jukhyang\",\"moju\",\"ihwa\"]\n",
    "\n",
    "for i in range(len(a3)):\n",
    "    bow_rep_tfidf = tfidf_fit.transform(globals()[a3[i]].doc)\n",
    "    word_count = pd.DataFrame({\n",
    "        '단어': tfidf.get_feature_names(),\n",
    "        'tf-idf': bow_rep_tfidf.sum(axis=0).flat,\n",
    "        'idf': tfidf.idf_\n",
    "    })\n",
    "\n",
    "    df3 = word_count.sort_values('tf-idf',ascending=False).head(50)[word_count['idf']>4.5][word_count['tf-idf'] * (len(all_data)/len(globals()[a3[i]]))>110]\n",
    "    df3.to_csv(f'막걸리_특징{i}.csv',encoding='utf-8-sig')\n",
    "\n",
    "    # for i in range(len(Tags)):\n",
    "    for j in df3['단어']:\n",
    "        Tags3[keys3[i]].append(j)\n",
    "Tags3['boksundoga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHashTagString(list_of_tags):\n",
    "\thashTagString = \"\"\n",
    "\n",
    "\tfor tag in list_of_tags:\n",
    "\t\thashTagString += \" #\" + tag\n",
    "\n",
    "\treturn hashTagString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(columns=['이름','해시태그'])\n",
    "a['이름'] = [\"감홍로\", \"금설\", \"증류주_더한매실원주_13도\", \"도원결의 15도\", \"도원결의 25도\", \"도원결의 40도\", \"박재서명인 안동소주 22도\",\n",
    "           \"박재서명인 안동소주 35도\", \"박재서명인 안동소주 45도\",\n",
    "            \"서울의밤 17도\", \"서울의밤 25도\",\"안동소주 일품 21도\",\"안동소주 일품 40도\",\"고헌정 동학 1957 특선 13도\",\"양촌양조 무농약 우렁이쌀\",\n",
    "            \"오메기 맑은술\",\"우포의아침\",\"복순도가\",\"배상면주가 느린마을 막걸리\",\"죽향도가\",\"모주\",\"술샘 이화주\",\n",
    "            \"금이산농원 복숭아 와인\",\"덕유양조 산머루주\",\"배상면주가 빙탄복\",\"산내들 소백산 스위트 와인\",\"컨츄리 와인 영동포도 와인\"]\n",
    "a['해시태그'] = [getHashTagString(Tags1['gamhonglo'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['geumsul'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['masil'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['dowon15'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['dowon25'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['dowon40'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['andong22'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['andong35'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['andong45'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['seoul17'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['seoul25'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['ilpum21'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags1['ilpum40'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags2['donghak'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags2['yangchon'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags2['omegi'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags2['upo'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags3['boksundoga'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags3['maeul'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags3['jukhyang'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags3['moju'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags3['ihwa'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags4['nongwon'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags4['duckyang'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags4['baesang'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags4['sobak'][0:3])[:].strip(),\n",
    "            getHashTagString(Tags4['yungdong'][0:3])[:].strip()]\n",
    "# a['field1'] = ['청주','청주','증류주','증류주','증류주','증류주','증류주','증류주','증류주','증류주','증류주','증류주','증류주','청주','청주','청주','청주',\n",
    "#                '막걸리','막걸리','막걸리','탁주','탁주','과실주','과실주','과실주','과실주','과실주']\n",
    "# a = a.sort_values(by='field1')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
