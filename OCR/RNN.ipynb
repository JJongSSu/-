{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "from konlpy.tag import Okt\n",
    "from nltk.util import everygrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원하는 태그 추출 & 불용어 제거\n",
    "okt = Okt()\n",
    "comment = okt.pos(\"댓글 데이터를 입력해주면 형태소 분석이 됩니다.\")\n",
    "\n",
    "#불용어\n",
    "stopwords = pd.read_csv('ko-stopwords.csv') #한국어불용어사전 불러오기\n",
    "stopwords=list(stopwords['stopwords']) \n",
    "stopwords.extend(['에서','고','이다','는','한','씨', \"것\",\"거\",\"게\",\"데\",\"이다\",\"건\",\"고\",\"되다\",\"되어다\",\"걸\",\"기\",\n",
    "                  \"시\",\"네\",\"듯\",\"랍니\",\"중이\",\"얘\",\"스\",\"도도\", \"나\",\"수\",\"개\",\"내\",\"기\",\"제\",\"저\",\"인\",\"있다\",\"이렇다\",\n",
    "                  \"그렇다\",\"번\",\"위\",\"팅\",\"분\",\"인\",\"링\",\"란\",\"포\",\"두\", \"진짜\", \"하다\" ,\"이다\" ,\"가다\", \"이제\" ,\"들다\",\n",
    "                 '에서','고','이다','젛','뇨','껀데','뭘'\n",
    "                 ,'최고','느리다','마을','최고','항상','포장','재다','말다','목','넘김','만족하다','정말','역시','아주','감사하다','오다','자주','요','늘','넘다','않다','더','병','다','숙성','나다','술','드리다','마트','꼼꼼하다','잇다'\n",
    "                 ,'복','순도','용','비싸다','가격','많다','강하다','보내다','추천','보고','쏘다','느낌','사다','처음','많이','톡','생각','엄청','날','아니다'\n",
    "                 ,'믿다', '구입', '사먹다', '한번', '싶다', '콤', '완전', '제품', '재', '해주다', '말', '사람','특별하다','언제나','빨르다','두번째','전','계속','달'\n",
    "                 ,'추석', '인생', '최애', '명절', '해', '중', '생각나다', '시원하다', '다르다', '알다', '가족', '정도', '기대', '친구', '괜찮다', '부모님', '지인', '아직'\n",
    "                 ,'만족스럽다', '빼다', '상품', '굿', '못', '도', '기분', '다시', '주다', '즐기다', '맞다', '맛보다', '제일', '집', '입맛', '모르다', '먹기'\n",
    "                 ,'조심하다', '따다', '차다', '엄마', '예정', '만족', '감', '일반', '파다', '막', '근데', '별로', '적당하다','예전', '가끔', '유명하다', '만', '뚜껑', '매우', '기대하다', '의사', '한잔', '신선하다', '느끼다', '그냥', '아쉽다'\n",
    "                 ,'오픈', '쎄다', '여자', '호불호', '꼭', '벌써', '버리다', '이렇게', '돼다', '크다', '느껴지다','고급', '종종', '어울리다', '알', '남편', '빨리', '어른', '소문', '아버지', '마시기', '할인', '살다' \n",
    "                 ,'풍부하다', '모임', '해드리다', '빠지다', '나서다', '원래', '아빠', '걸리다', '안', '도착', '없이'\n",
    "                 ,'하루', '딱이다', '상태', '향', '후', '설', '주변', '사서', '때문', '반하다', '연말'\n",
    "                 ,'해봤다', '강추', '찾다', '자꾸', '살짝', '몇번', '빨', '요즘', '신세계', '사진', '생일'\n",
    "                 ,'빠르다', '자다', '구매', '마시다', '받다', '보다', '없다', '새다', '숙취', '아스파탐', '대포', '넘어가다','주가'\n",
    "                 ,'지나다', '무', '머리', '편하다', '아프다', '두다', '인터넷', '택배', '숙성하다', '일주일', '봄', '배달', '만들다', '애용', '냉장고' \n",
    "                 ,'여름', '잔', '앞', '며칠', '팔다', '달라지다', '가장', '변하다', '번창', '안전하다', '젤', '배상면', '건강하다', '굿굿'\n",
    "                 ,'따르다', '이용', '확실하다', '날짜', '시중', '들어가다', '첨가', '유통', '아이스팩', '제조', '넣다', '생', '다양하다','종류','들어가다','전통주','마켓','술술','후기','사보다','부담','여러가지','리뷰','블루'\n",
    "                 ,'인기','궁금하다','대상','무난','취향','적다','단','평이','이용','터지다','맘'\n",
    "                 ]\n",
    "                 +'회랑 회 따뜻하다 나쁘다 튼튼하다 끄다 끝 장인어른 일품 파손 싸다 술맛 비다 착하다 명인 증류 안동소주 안동 뒤끝 박다 신랑 비다 뒤끝 품질 짜다 용이 외국인 지고 지다 높다 어르신 신분 명인 보이다 준비 쇼핑 밤 서울 실향 스컬 낮다 가볍다 섞다 귀엽다 명랑 버전 꼼꼼 볼 대중 패키지 높다 하이 널 타 써다 집들이 실향 원주 긋다 술맛 술집 패키지 결의 증류주 섞다 타 이름 인공 약 높다 감기 대중 인위 짜다 막걸리 대접 볼 관심 타 남다 기회 하이 볼 섞다 향기 도주 집들이 독하다 이름 파티 어떻다 워낙 보기 마치다 가미 다기 수고 맛잇을걱닡아 모으다 햡 담날 대박 물맛 안되다 읺았어 짜다 빠져들다 소비 안나 이색 보리 빨랏 부족하다 화이팅 편 감홍 쇼핑 대다 도자기 생신 술맛 지다 높다 개봉 준비 깊다 볼 외국 아버님 조명 이벤트 용이 얼 눈 신분 보기 작다 내기 불빛 사은 비주 즐겁다 준비 생신 아깝다 주신 싸다 품 아버님 비쥬 조명도 반응 켜다 고맙다 동학 저렴하다 청 서비스 술잔 소주 강쇠주 오메 기술 조선 대비 요리 사용 데우다 조사 쓰다 감사 음식 알콜 경험 청주 강쇠 가성 전주 모주 뜨다 신기하다 화주 좋아하다 주문 예쁘다 이쁘다 얼음 산 토닉 워터 빨대 깨지다 빙 탄복 박스 약하다 국산 오프너 위트 소백산 제공 분위기 아내 크리스마스 마음 마루 베베 솔직하다 초보자 와이프 작성 위트 디자인 굳다 달다 시큼하다 달달 선물 깔끔하다 뒤 비비 이 있 하 것 들 그 되 수 이 보 않 없 나 사람 주 아니 등 같 우리 때 년 가 한 지 대하 오 말 일 그렇 위하 기한 달라 첫날 첨 주말 걱정 전이 이유 해보다 저번 보지 함 기대다 상 비 베스트 도수 음 존맛 개인'.split()\n",
    "                 ) #불용어 추가\n",
    "stopwords=set(stopwords) # 중복제거    \n",
    "\n",
    "# 형태소 분석 함수 만들기\n",
    "def okt_pos_tagging2(string):\n",
    "    pos_words = okt.pos(string, stem=True, norm=True) # 형태소 분석. 단어는 사전형으로 바꿔주기\n",
    "    words = [word for word, tag in pos_words if tag \n",
    "             in ['Noun', 'Adjective', 'Verb','Adverb'] if word not in stopwords ]\n",
    "\n",
    "    # n_gram 만들기\n",
    "    egram = list(everygrams(words, min_len=1, max_len=1))\n",
    "    egram_token = [' '.join(grams) for grams in egram]\n",
    "\n",
    "    return egram_token\n",
    "\n",
    "def okt_pos_tagging(string):\n",
    "    pos_words = okt.pos(string, stem=True, norm=True) # 형태소 분석. 단어는 사전형으로 바꿔주기\n",
    "    words = [word for word, tag in pos_words if tag \n",
    "             in ['Noun', 'Adjective', 'Verb','Adverb'] if word not in stopwords ]\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14728\\303412373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_percent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m \u001b[1;31m# 테스트 데이터 비율\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 훈련 데이터와 테스트 데이터 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_percent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_percent = 0.2 # 테스트 데이터 비율\n",
    "# 훈련 데이터와 테스트 데이터 생성\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import models\n",
    "\n",
    "def build_model(train_data): # to make rnn model\n",
    "    train_data = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1,), dtype=\"string\")) # input one string data (comment)\n",
    "    max_tokens = 15000 # dictionary size\n",
    "    max_len = 50 # comment to vectorize size\n",
    "    vectorize_layer = TextVectorization( # make textvectorization \n",
    "      max_tokens=max_tokens,\n",
    "      output_mode=\"int\",\n",
    "      output_sequence_length=max_len,\n",
    "    )\n",
    "    \n",
    "    vectorize_layer.adapt(train_data.batch(64))\n",
    "    model.add(vectorize_layer)\n",
    "    model.add(layers.Embedding(max_tokens + 1,output_dim= 200))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14728\\3234438857.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mrnn_model\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 모델 생성 함수를 통해 모델 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m rnn_model.compile( # rnn model compile 컴파일 진행\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 최적화 함수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "rnn_model =build_model(x_train) # 모델 생성 함수를 통해 모델 생성\n",
    "rnn_model.compile( # rnn model compile 컴파일 진행\n",
    "        optimizer=  \"adam\",  # 최적화 함수\n",
    "        loss='binary_crossentropy', # 손실 함수\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "# model training\n",
    "history = rnn_model.fit(x_train,y_train, #훈련시키기\n",
    "                   epochs = 5,  batch_size = 128  , validation_data = (x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
